{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Agent 2\n",
    "\n",
    "\n",
    "### Patterns \n",
    "\n",
    "   - Reflection : 자기 비판\n",
    "   - Reflexion : 현재 답변의 약점 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pattern 1 : Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 블로그를 평가하는 인플루언서입니다. 사용자의 글에 대한 비평과 추천을 생성하세요.\"\n",
    "            \"길이, 바이럴율, 스타일 등에 대한 요청을 포함하여 자세한 추천을 제공하세요.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 게시물을 작성하는 업무를 맡은 기술 인플루언서의 보조자입니다.\"\n",
    "            \" 사용자의 요청에 따라 최상의 게시물을 작성하세요.\"\n",
    "            \" 사용자가 비평을 제공하면, 이전 시도를 수정하여 250개 단어로 답변하세요.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "generate_chain = generation_prompt | llm\n",
    "reflect_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECT = \"reflect\"\n",
    "GENERATE = \"generate\"\n",
    "\n",
    "\n",
    "def generation_node(state: Sequence[BaseMessage]):\n",
    "    return generate_chain.invoke({\"messages\": state})\n",
    "\n",
    "\n",
    "def reflection_node(messages: Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    res = reflect_chain.invoke({\"messages\": messages})\n",
    "    return [HumanMessage(content=res.content)]\n",
    "\n",
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(GENERATE, generation_node)\n",
    "builder.add_node(REFLECT, reflection_node)\n",
    "builder.set_entry_point(GENERATE)\n",
    "\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    if len(state) > 6:\n",
    "        return END\n",
    "    return REFLECT\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(GENERATE, should_continue)\n",
    "builder.add_edge(REFLECT, GENERATE)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = HumanMessage(content=\"\"\"다음의 블로그 내용을 더 멋지게 만들어 주세요:\"\n",
    "\n",
    "            — Agentic AI는 최근 LLM 기반 시스템의 진화된 형태로, **\"자율적이고 목표 지향적인 행동을 할 수 있는 AI\"**를 말합니다. \n",
    "\n",
    "                                  \"\"\")\n",
    "response = graph.invoke(inputs)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pattern 2 : Reflexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.output_parsers import JsonOutputToolsParser, PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"누락된 부분에 대한 비판\")\n",
    "    superfluous: str = Field(description=\"불필요한 것에 대한 비판\")\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the question.\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"질문에 대한 답변은 250자 내로 작성\")\n",
    "    reflection: Reflection = Field(description=\"첫 번째 답변에 대한 평가\")\n",
    "    search_queries: List[str] = Field(\n",
    "        description=\"현재 답변에 대한 비판을 해결하기 위한 개선 사항을 조사하기 위한 1~3개의 검색어\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question.\"\"\"\n",
    "\n",
    "    references: List[str] = Field(\n",
    "        description=\"업데이트된 답변에 대한 동기를 인용\"\n",
    "    )\n",
    "\n",
    "def run_queries(search_queries: list[str], **kwargs):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n",
    "\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    [\n",
    "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
    "        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = JsonOutputToolsParser(return_id=True)\n",
    "\n",
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"당신은 전문적인 연구자입니다.\n",
    "                Current time: {time}\n",
    "\n",
    "                1. {first_instruction}\n",
    "                2. 답변을 되돌아보고 비판하세요. 개선을 극대화하기 위해 진지하게 비판하세요.\n",
    "                3. 정보를 확인하고 답변을 개선하기 위해 검색어를 추천하세요\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\", \"사용자의 질문에 필요한 형식을 사용하여 답변하세요.\"),\n",
    "    ]\n",
    ").partial(\n",
    "    time=lambda: datetime.datetime.now().isoformat(),\n",
    ")\n",
    "\n",
    "\n",
    "first_responder = actor_prompt_template.partial(\n",
    "    first_instruction=\"250자 내로 자세한 답변을 하세요.\"\n",
    ") | llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"AnswerQuestion\")\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
    "\n",
    "\n",
    "revise_instructions = \"\"\"새로운 정보를 사용하여 이전 답변을 수정하세요.\n",
    "                        - 이전 비평을 활용하여 답변에 중요한 정보를 추가하세요.\n",
    "                            - 수정된 답변의 검증을 위해 반드시 인용 번호를 포함하세요.\n",
    "                            - 답변 하단에 \"참고문헌\" 섹션을 추가하세요(참고문헌은 단어 제한에 포함되지 않습니다). 다음 형식으로 작성하세요:\n",
    "                                - [1] https://example.com\n",
    "                                - [2] https://example.com\n",
    "                        - 이전 비평을 활용하여 답변에서 불필요한 정보를 제거하고 250 단어를 넘지 않도록 작성하세요.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "revisor = actor_prompt_template.partial(\n",
    "    first_instruction=revise_instructions\n",
    ") | llm.bind_tools(tools=[ReviseAnswer], tool_choice=\"ReviseAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 2\n",
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\"draft\", first_responder)\n",
    "builder.add_node(\"execute_tools\", tool_node)\n",
    "builder.add_node(\"revise\", revisor)\n",
    "builder.add_edge(\"draft\", \"execute_tools\")\n",
    "builder.add_edge(\"execute_tools\", \"revise\")\n",
    "\n",
    "\n",
    "def event_loop(state: List[BaseMessage]) -> str:\n",
    "    count_tool_visits = sum(isinstance(item, ToolMessage) for item in state)\n",
    "    num_iterations = count_tool_visits\n",
    "    if num_iterations > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\"\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"revise\", event_loop)\n",
    "builder.set_entry_point(\"draft\")\n",
    "graph = builder.compile()\n",
    "\n",
    "# print(graph.get_graph().draw_mermaid())\n",
    "# print(graph.get_graph().draw_ascii())\n",
    "\n",
    "graph.get_graph().draw_mermaid_png(output_file_path=\"graph.png\")\n",
    "\n",
    "res = graph.invoke(\n",
    "    \"NPU에 대한 고충 영역을 식별하고 이를 해결하기 위해 자본 투자를 유치한 스타트업 목록을 나열하세요.\"\n",
    ")\n",
    "print(res[-1].tool_calls[0][\"args\"][\"answer\"])\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
