{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgraph\n",
    "\n",
    "1. ì„œë¸Œ ê·¸ë˜í”„ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ë…¸ë“œ ì¶”ê°€\n",
    "2. í•˜ìœ„ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ê°€ ìˆëŠ” ë…¸ë“œë¥¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì„œë¸Œ ê·¸ë˜í”„ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ë…¸ë“œ ì¶”ê°€\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str  \n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    foo: str  \n",
    "    bar: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë¸Œ ê·¸ë˜í”„ ì •ì˜\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"subgraph_node\", subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "\n",
    "# ë¶€ëª¨ ê·¸ë˜í”„ ì •ì˜\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"subgraph\", subgraph)\n",
    "builder.add_edge(START, \"subgraph\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"foo\": \"hello\"}\n",
    "result = graph.invoke(initial_state)\n",
    "print(f\"Result: {result}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ë‘ë²ˆì§¸ ë°©ë²•\n",
    "2. í•˜ìœ„ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ê°€ ìˆëŠ” ë…¸ë“œë¥¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "\n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    # ë¶€ëª¨ì˜ ê·¸ë˜í”„ ìƒíƒœì™€ í‚¤ë¥¼ ê³µìœ í•˜ì§€ ì•ŠìŒ\n",
    "    bar: str\n",
    "    baz: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë¸Œ ê·¸ë˜í”„ ì •ì˜\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"bar\": state[\"bar\"] + \"baz\"}\n",
    "\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"subgraph_node\", subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
    "subgraph = subgraph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë¸Œ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ëŠ” ë¶€ëª¨ ê·¸ë˜í”„ ì •ì˜\n",
    "def node(state: State):\n",
    "    response = subgraph.invoke({\"bar\": state[\"foo\"]})\n",
    "    # ë¶€ëª¨ ìƒíƒœë¡œ ì‘ë‹µê°’ì„ ë³€í™˜\n",
    "    return {\"foo\": response[\"bar\"]}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node\", node)\n",
    "builder.add_edge(START, \"node\")\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"foo\": \"hello\"}\n",
    "result = graph.invoke(initial_state)\n",
    "print(\n",
    "    f\"Result: {result}\"\n",
    ")  # Should transform foo->bar, append \"baz\", then transform bar->foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain.tools import tool\n",
    "from typing import TypedDict, List, Annotated\n",
    "from langgraph.graph.message import add_messages  # âœ… ë©”ì‹œì§€ ë³‘í•© í•¨ìˆ˜\n",
    "\n",
    "# 0. ëª…ì‹œì  ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2. ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Return company headcounts based on a simulated web search.\"\"\"\n",
    "    return (\n",
    "        \"Here are the headcounts for each of the FAANG companies in 2024:\\n\"\n",
    "        \"1. **Facebook (Meta)**: 67,317 employees.\\n\"\n",
    "        \"2. **Apple**: 164,000 employees.\\n\"\n",
    "        \"3. **Amazon**: 1,551,000 employees.\\n\"\n",
    "        \"4. **Netflix**: 14,000 employees.\\n\"\n",
    "        \"5. **Google (Alphabet)**: 181,269 employees.\"\n",
    "    )\n",
    "\n",
    "# 3. ì—ì´ì „íŠ¸ ìƒì„±\n",
    "math_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[add, multiply],\n",
    "    name=\"math_expert\",\n",
    "    prompt=\"You are a math expert. Always use one tool at a time.\"\n",
    ")\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[web_search],\n",
    "    name=\"research_expert\",\n",
    "    prompt=\"You are a world class researcher with access to web search. Do not do any math.\"\n",
    ")\n",
    "\n",
    "# 4. Supervisor ë…¸ë“œ í•¨ìˆ˜ ì •ì˜\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    last_message = state[\"messages\"][-1].content.lower()\n",
    "\n",
    "    if \"headcount\" in last_message:\n",
    "        # ì²« ìš”ì²­ â†’ ë¦¬ì„œì¹˜\n",
    "        if \"combined\" in last_message or \"total\" in last_message:\n",
    "            if \"research_done\" not in state:\n",
    "                return {\"__next__\": \"research_expert\", \"research_done\": True}\n",
    "            else:\n",
    "                return {\"__next__\": \"math_expert\"}\n",
    "    return {\"__next__\": END}\n",
    "\n",
    "# 5. ê·¸ë˜í”„ êµ¬ì„±\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"math_expert\", math_agent)\n",
    "graph.add_node(\"research_expert\", research_agent)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "graph.add_edge(\"supervisor\", \"math_expert\")\n",
    "graph.add_edge(\"supervisor\", \"research_expert\")\n",
    "graph.add_edge(\"math_expert\", END)\n",
    "graph.add_edge(\"research_expert\", END)\n",
    "\n",
    "# 6. ì»´íŒŒì¼ ë° ì‹¤í–‰\n",
    "app = graph.compile()\n",
    "\n",
    "# 7. ì‹¤í–‰\n",
    "output = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"2024ë…„ FAANG ê¸°ì—…ì˜ ì´ ì§ì› ìˆ˜ëŠ” ì–¼ë§ˆì…ë‹ˆê¹Œ? ì „ì²´ í•˜ë‚˜ì˜ ìˆ˜ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\")]\n",
    "})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "from langchain_core.messages import get_buffer_string\n",
    "print(get_buffer_string(output[\"messages\"]))\n",
    "\n",
    "last_msg = output[\"messages\"][-1]\n",
    "print(\"ğŸ§¾ Final answer:\\n\", last_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langgraph langgraph-supervisor langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
