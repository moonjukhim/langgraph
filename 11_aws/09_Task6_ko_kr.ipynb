{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adba6786",
   "metadata": {},
   "source": [
    "# 태스크 6: LangGraph와 Bedrock 모델 통합\n",
    "\n",
    "이 노트북에서는 에이전트가 사용할 수 있는 도구를 사용하여 작업 순서를 결정하고, 이를 구현하는 계획 및 실행 에이전트를 사용하는 방법을 알아보겠습니다. \n",
    "\n",
    "특정 애플리케이션은 사용자의 질문에 답변하기 위해 언어 모델과 다양한 유틸리티에 대한 적응 가능한 호출 순서를 요구합니다. LangChain 에이전트 인터페이스는 유연하며, 외부 도구와 LLM의 추론을 통합할 수 있습니다. 에이전트는 사용자 입력에 따라 사용할 도구를 선택할 수 있습니다. 에이전트는 여러 도구를 사용할 수 있으며 한 도구의 출력을 다음 도구의 입력으로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af1034",
   "metadata": {},
   "source": [
    "## 태스크 6.1: 환경 설정\n",
    "\n",
    "이 태스크에서는 환경을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d84aafc-24b9-4129-86b1-4b06a9016821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:53:20.975676Z",
     "iopub.status.busy": "2025-10-16T03:53:20.975287Z",
     "iopub.status.idle": "2025-10-16T03:53:22.530680Z",
     "shell.execute_reply": "2025-10-16T03:53:22.529849Z",
     "shell.execute_reply.started": "2025-10-16T03:53:20.975643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.27\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: jupyter_ai_magics, langchain-community\n",
      "---\n",
      "Name: langchain-core\n",
      "Version: 0.3.79\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity, typing-extensions\n",
      "Required-by: amazon_sagemaker_jupyter_ai_q_developer, langchain, langchain-aws, langchain-community, langchain-text-splitters, langgraph, langgraph-checkpoint, langgraph-prebuilt\n",
      "---\n",
      "Name: langgraph\n",
      "Version: 0.6.10\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain langchain-core langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "717585b7-b0c0-4a30-be49-e0716716b5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:09:01.614492Z",
     "iopub.status.busy": "2025-10-16T07:09:01.614175Z",
     "iopub.status.idle": "2025-10-16T07:09:02.423397Z",
     "shell.execute_reply": "2025-10-16T07:09:02.422638Z",
     "shell.execute_reply.started": "2025-10-16T07:09:01.614466Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import pandas as pd\n",
    "import numexpr\n",
    "\n",
    "# LangChain / LangGraph imports\n",
    "from langchain.tools import tool\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96bd8701-e959-401b-b066-2ad2acea9542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:03.436509Z",
     "iopub.status.busy": "2025-10-16T07:15:03.436136Z",
     "iopub.status.idle": "2025-10-16T07:15:03.449117Z",
     "shell.execute_reply": "2025-10-16T07:15:03.448140Z",
     "shell.execute_reply.started": "2025-10-16T07:15:03.436486Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 🧰 Tools 정의\n",
    "# ----------------------------------------\n",
    "\n",
    "@tool\n",
    "def lookup_price(item_name: str) -> str:\n",
    "    \"\"\"Lookup the price of a product by its name from the CSV file.\"\"\"\n",
    "    df = pd.read_csv(\"sales.csv\")\n",
    "    result = df[df[\"item\"] == item_name]\n",
    "    if result.empty:\n",
    "        return f\"'{item_name}' not found.\"\n",
    "    return str(result[\"price\"].values[0])\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression and return the result as a string.\"\"\"\n",
    "    try:\n",
    "        result = numexpr.evaluate(expression)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def echo_tool(text: str) -> str:\n",
    "    \"\"\"Echo back the provided text.\"\"\"\n",
    "    return f\"Echo: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb6f6fda-2b57-4d5b-a43a-c82d21215084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:05.981585Z",
     "iopub.status.busy": "2025-10-16T07:15:05.981260Z",
     "iopub.status.idle": "2025-10-16T07:15:05.994358Z",
     "shell.execute_reply": "2025-10-16T07:15:05.993630Z",
     "shell.execute_reply.started": "2025-10-16T07:15:05.981541Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 🧩 Agent Node 생성\n",
    "# ----------------------------------------\n",
    "\n",
    "# Bedrock 모델 (또는 호환 모델)\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",\n",
    "    region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37a1ddab-343c-46a2-b2e9-d05550981474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:06.909453Z",
     "iopub.status.busy": "2025-10-16T07:15:06.909178Z",
     "iopub.status.idle": "2025-10-16T07:15:06.925904Z",
     "shell.execute_reply": "2025-10-16T07:15:06.925135Z",
     "shell.execute_reply.started": "2025-10-16T07:15:06.909433Z"
    }
   },
   "outputs": [],
   "source": [
    "# 사용할 도구 리스트\n",
    "tools = [lookup_price, calculator, echo_tool]\n",
    "\n",
    "# create_react_agent: LLM이 ToolNode를 통해 도구를 호출하도록 자동 구성\n",
    "agent = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4063c43-3120-44a1-b126-a288696179a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:09.928879Z",
     "iopub.status.busy": "2025-10-16T07:15:09.928614Z",
     "iopub.status.idle": "2025-10-16T07:15:13.695201Z",
     "shell.execute_reply": "2025-10-16T07:15:13.694363Z",
     "shell.execute_reply.started": "2025-10-16T07:15:09.928859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LangGraph ReAct Agent Example ===\n",
      "\n",
      "\n",
      "🤖 Agent Response:\n",
      "<thinking> The 'echo_tool' confirms that the item names are being correctly passed to the tools. However, the 'lookup_price' tool still seems to be malfunctioning. I will need to inform the user about the issue and suggest they check back later or contact support for assistance. </thinking>\n",
      "\n",
      "<response> I'm sorry, but I'm currently unable to look up the prices of the items due to a technical issue with the 'lookup_price' tool. Please check back later or contact support for assistance. </response>\n"
     ]
    }
   ],
   "source": [
    "print(\"=== LangGraph ReAct Agent Example ===\\n\")\n",
    "user_input = \"사용자 질문:How much will it cost to buy 3 units of P002 and 5 units of P003?\"\n",
    "\n",
    "# ✅ agent 자체가 실행 가능한 Graph입니다\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "\n",
    "print(\"\\n🤖 Agent Response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef24bea",
   "metadata": {},
   "source": [
    "## 태스크 6.2: Synergizing Reasoning and Acting in Language Models 프레임워크\n",
    "\n",
    "이 태스크에서 ReAct 프레임워크는 대규모 언어 모델이 외부 도구와 상호 작용하여 보다 더 정확하고 사실에 기반한 응답을 제공하는 추가 정보를 얻을 수 있게 합니다.\n",
    "\n",
    "대규모 언어 모델은 추론에 대한 설명과 작업별 응답을 교대로 생성할 수 있습니다.\n",
    "\n",
    "추론 설명을 생성하면 모델이 실행 계획을 추론, 모니터링 및 수정할 수 있고, 예상치 못한 시나리오도 처리할 수도 있습니다. 실행 단계에서 모델은 지식 기반 또는 환경과 같은 외부 소스와 인터페이스를 통해 정보를 획득할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1defc7f-4475-4071-9ab3-ff5806d068d1",
   "metadata": {},
   "source": [
    "다음 셀에서는 Langchain 프레임워크 내에서 도구 역할을 하는 `calculator` 함수를 정의합니다. 이 도구는 언어 모델이 Python의 numexpr 라이브러리를 사용해 주어진 식을 평가하여 수학적 계산을 수행할 수 있게 합니다. 이 도구는 식이 유효하지 않은 경우를 처리하도록 설계되었습니다. 이 경우, 이 도구는 계산에 대한 접근 방식 재고하도록 모델에 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6155c82-eb40-4eff-b5d5-d9fec4905278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:56:45.279830Z",
     "iopub.status.busy": "2025-10-16T03:56:45.279513Z",
     "iopub.status.idle": "2025-10-16T03:56:45.291514Z",
     "shell.execute_reply": "2025-10-16T03:56:45.290747Z",
     "shell.execute_reply.started": "2025-10-16T03:56:45.279808Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def lookup_price(query: str) -> str:\n",
    "    \"\"\"Look up a product price from a CSV file.\n",
    "    Expected query: product_id (or line with product_id on first line)\n",
    "    The original notebook used a CSV file; adapt the path as needed.\n",
    "    \"\"\"\n",
    "    csv_path = os.environ.get(\"PRICES_CSV\", \"prices.csv\")\n",
    "    prices = {}\n",
    "    if not os.path.exists(csv_path):\n",
    "        return f\"Price CSV not found at {csv_path}\"\n",
    "    try:\n",
    "        with open(csv_path, newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                prices[row.get('product_id') or row.get('id')] = row.get('price')\n",
    "    except Exception as e:\n",
    "        return f\"Failed to read CSV: {e}\"\n",
    "\n",
    "    qstr = query.split('\\n')[0].strip()\n",
    "    price = prices.get(qstr)\n",
    "    if price is None:\n",
    "        return f\"Price for product {qstr} is not available\"\n",
    "    return f\"Price of product {qstr} is {price}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce2b82-438c-4b13-a941-74c79d6526c3",
   "metadata": {},
   "source": [
    "다음 셀에서는 Langchain 프레임워크 내에서 도구 역할을 하는 `calculator` 함수를 정의합니다. 이 도구를 사용하면 언어 모델에서 Python의 numexpr 라이브러리를 통해 주어진 표현식을 평가하여 수학적 계산을 수행할 수 있습니다. 표현식이 유효하지 않은 사례가 처리되도록 도구가 설계되었습니다. 해당 사례에서는 계산에 대한 접근 방식 재고를 모델에 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4c3256c-0806-4a19-ad42-4a2153f9ea9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:57:03.116611Z",
     "iopub.status.busy": "2025-10-16T03:57:03.116272Z",
     "iopub.status.idle": "2025-10-16T03:57:03.122942Z",
     "shell.execute_reply": "2025-10-16T03:57:03.122081Z",
     "shell.execute_reply.started": "2025-10-16T03:57:03.116589Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a math expression and return the result as string.\n",
    "    Uses numexpr for basic arithmetic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # strip natural-language wrappers if user sent 'compute: 5*4' etc.\n",
    "        expr = expression.strip()\n",
    "        # Evaluate using numexpr to limit operations\n",
    "        result = numexpr.evaluate(expr, global_dict={}, local_dict={})\n",
    "        return str(result)\n",
    "    except Exception:\n",
    "        return \"Error evaluating expression. Please provide a valid math expression.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ad97004-e7b8-4479-b966-2b276f8e55ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:59:13.468032Z",
     "iopub.status.busy": "2025-10-16T03:59:13.467741Z",
     "iopub.status.idle": "2025-10-16T03:59:13.487631Z",
     "shell.execute_reply": "2025-10-16T03:59:13.486990Z",
     "shell.execute_reply.started": "2025-10-16T03:59:13.468009Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def echo_tool(text: str) -> str:\n",
    "    \"\"\"Lookup the price of a product by its name from the CSV file.\"\"\"\n",
    "    return text\n",
    "\n",
    "# Bind tools to the LLM\n",
    "tools = [lookup_price, calculator, echo_tool]\n",
    "tools_by_name = {t.name: t for t in tools}\n",
    "llm_with_tools = chat_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "642ed754-8a53-4485-8164-aab5f8be60a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:10:46.554372Z",
     "iopub.status.busy": "2025-10-16T05:10:46.554109Z",
     "iopub.status.idle": "2025-10-16T05:10:46.561264Z",
     "shell.execute_reply": "2025-10-16T05:10:46.560519Z",
     "shell.execute_reply.started": "2025-10-16T05:10:46.554351Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 3: Define shared state type ---\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int\n",
    "\n",
    "# --- Step 4: Define nodes ---\n",
    "# Model node: ask the model to decide next step / produce a message\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant. Use the available tools when needed.\"\n",
    "\n",
    "def llm_node(state: MessagesState):\n",
    "    \"\"\"Call the LLM (with tools) and append its response to state['messages']\"\"\"\n",
    "    # Build messages: include a system message followed by the conversation\n",
    "    msgs = [SystemMessage(content=SYSTEM_PROMPT)] + state.get(\"messages\", [])\n",
    "    response = llm_with_tools.invoke(msgs)\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"llm_calls\": state.get(\"llm_calls\", 0) + 1,\n",
    "    }\n",
    "\n",
    "# Tool node: execute tool calls that the LLM requested\n",
    "def tool_node(state: MessagesState):\n",
    "    \"\"\"Perform any tool calls found on the last LLM message and return ToolMessage objects.\"\"\"\n",
    "    result = []\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        return {\"messages\": []}\n",
    "\n",
    "    last = messages[-1]\n",
    "    # In LangChain message objects, tool calls live in `.tool_calls` on the message\n",
    "    tool_calls = getattr(last, \"tool_calls\", []) or []\n",
    "    for tool_call in tool_calls:\n",
    "        # tool_call expected shape: {\"name\": ..., \"args\": ...}\n",
    "        tool_name = tool_call.get(\"name\")\n",
    "        args = tool_call.get(\"args\", {})\n",
    "        if tool_name not in tools_by_name:\n",
    "            obs = f\"Tool {tool_name} not found\"\n",
    "        else:\n",
    "            obs = tools_by_name[tool_name].invoke(args)\n",
    "        # Create a ToolMessage with the observation\n",
    "        tm = ToolMessage(content=obs, tool_call_id=tool_call.get(\"id\"))\n",
    "        result.append(tm)\n",
    "    return {\"messages\": result}\n",
    "\n",
    "# --- Step 5: Edge decision function: continue if model made a tool call ---\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        return END\n",
    "    last = messages[-1]\n",
    "    if getattr(last, \"tool_calls\", None):\n",
    "        return \"tool_node\"\n",
    "    return END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a0ac1-d256-4188-b6b7-22a5f6960d34",
   "metadata": {},
   "source": [
    "다음 셀에서는 helper 함수를 실행하여 추적 출력을 파일에 인쇄합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5321facb-cfc9-4e86-a669-db6dbdf116b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:10:55.626253Z",
     "iopub.status.busy": "2025-10-16T05:10:55.625980Z",
     "iopub.status.idle": "2025-10-16T05:10:55.631038Z",
     "shell.execute_reply": "2025-10-16T05:10:55.630178Z",
     "shell.execute_reply.started": "2025-10-16T05:10:55.626229Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "def output_trace(element:str, trace, node=True):\n",
    "    global trace_handle\n",
    "    if trace_enabled:\n",
    "        print(datetime.datetime.now(),file=trace_handle)\n",
    "        print((\"Node: \" if node else \"Edge: \")+ element, file=trace_handle)\n",
    "        if element == \"ask_model_to_reason (entry)\":\n",
    "            for single_trace in trace:\n",
    "                print(single_trace, file=trace_handle)\n",
    "        else:\n",
    "            print(trace, file=trace_handle)\n",
    "        print('----', file=trace_handle)\n",
    "        \n",
    "def consolidate_tool_messages(message):\n",
    "    tool_messages=[]\n",
    "    for msg in message:\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            tool_messages.append(msg)\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320f3b2",
   "metadata": {},
   "source": [
    "## 태스크 6.3: 에이전트 그래프 구축\n",
    "\n",
    "이 태스크에서는 외부 도구와 상호 작용할 수 있는 대화형 AI 시스템용 에이전트 그래프를 생성하게 됩니다. 에이전트 그래프는 도구와의 대화 및 상호 작용 흐름이 정의되는 상태 머신입니다.\n",
    "\n",
    "다음 셀에서는 입력에 따라 상태를 업데이트하는 관련 함수가 있는 노드를 정의합니다. 그래프가 한 노드에서 다음 노드로 전환되는 가장자리를 사용하여 노드를 연결합니다. 조건부 에지를 통합하여 특정 조건에 따라 그래프를 다른 노드로 라우팅합니다. 마지막으로 에이전트 그래프를 컴파일하여 정의된 대로 전환 및 상태 업데이트를 처리하여 실행을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b51b843-3660-4929-bbc9-af859be41260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:11:44.300200Z",
     "iopub.status.busy": "2025-10-16T05:11:44.299923Z",
     "iopub.status.idle": "2025-10-16T05:11:44.307613Z",
     "shell.execute_reply": "2025-10-16T05:11:44.306817Z",
     "shell.execute_reply.started": "2025-10-16T05:11:44.300178Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 6: Build and compile the StateGraph ---\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "agent_builder.add_node(\"llm_node\", llm_node)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# Connect start to llm_node\n",
    "agent_builder.add_edge(START, \"llm_node\")\n",
    "# Conditional: if llm created tool calls -> tool_node else END\n",
    "agent_builder.add_conditional_edges(\"llm_node\", should_continue, [\"tool_node\", END])\n",
    "# After executing tools, go back to llm\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_node\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db097971-db69-4c8f-a08a-9686b5a1ad72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:13:13.994398Z",
     "iopub.status.busy": "2025-10-16T05:13:13.994118Z",
     "iopub.status.idle": "2025-10-16T05:13:15.885394Z",
     "shell.execute_reply": "2025-10-16T05:13:15.884702Z",
     "shell.execute_reply.started": "2025-10-16T05:13:13.994377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking agent with example messages...\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 5*7?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "P001\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"<thinking>The User has asked for a simple multiplication calculation. The 'calculator' tool can be used to safely evaluate the expression.</thinking>\\n\"}, {'type': 'tool_use', 'name': 'calculator', 'input': {'expression': '5*7'}, 'id': 'tooluse_eCrh6WQdSxOQxmqGlD0Cyg'}]\n",
      "Tool Calls:\n",
      "  calculator (tooluse_eCrh6WQdSxOQxmqGlD0Cyg)\n",
      " Call ID: tooluse_eCrh6WQdSxOQxmqGlD0Cyg\n",
      "  Args:\n",
      "    expression: 5*7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "35\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of the multiplication 5 * 7 is 35.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "user_messages = [HumanMessage(content=\"What is 5*7?\"), HumanMessage(content=\"P001\")]\n",
    "initial_state = {\"messages\": user_messages, \"llm_calls\": 0}\n",
    "\n",
    "print(\"Invoking agent with example messages...\\n\")\n",
    "out = agent.invoke(initial_state)\n",
    "# The agent returns a dict-like state; print messages\n",
    "messages_out = out.get(\"messages\", [])\n",
    "for m in messages_out:\n",
    "    try:\n",
    "        m.pretty_print()\n",
    "    except Exception:\n",
    "        print(repr(m))\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ba496-f4e8-459c-a8e0-1add96724640",
   "metadata": {},
   "source": [
    "다음으로 컴파일된 그래프를 시각화합니다. 점선으로 표시된 것처럼 에이전트 노드에서 조건부로 전환되는 것을 관찰합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe11dc-4a20-4f82-82a0-7a2b21261ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(react_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12e190-6682-422b-a7e7-902baeab368f",
   "metadata": {},
   "source": [
    "다음 셀에서는 helper 함수를 실행하여 그래프 출력을 인쇄합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e1a56-983e-4fb7-95e2-f1045d22bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a02d2-d337-40cd-ae33-52d168954345",
   "metadata": {},
   "source": [
    "다음으로 이전 노트북에서 생성한 sales.csv 파일에서 에이전트에게 제품 가격에 대해 물어보고 싶은 질문을 하나 이상 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93542a4-00e1-4778-801f-54000bedd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of questions\n",
    "questions=[]\n",
    "questions.append(\"How much will it cost to buy 3 units of P002 and 5 units of P003?\")\n",
    "#questions.append(\"How many units of P010 can I buy with $200?\")\n",
    "#questions.append(\"Can I buy three units of P003 with $200? If not, how much more should I spend to get three units?\")\n",
    "#questions.append(\"Prices have gone up by 8%. How many units of P003 could I have purchased before the price increase with $140? How many can I buy after the price increase? Fractional units are not pssoible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2fdc8-7491-4b9b-a7b7-d4f7b909140b",
   "metadata": {},
   "source": [
    "추론에 포함된 단계를 이해하려면 추적을 활성화합니다. 그러나, 위 목록에서 **한 개의 질문을 제외한 모든 질문을 주석 처리**하여 추적 출력을 관리하기 쉽게 유지합니다. 또는 추적을 비활성화하고 모든 질문을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286029b4-a16c-405c-9280-961c1e9378a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_enabled=True\n",
    "\n",
    "if trace_enabled:\n",
    "    file_name=\"trace_\"+str(datetime.datetime.now())+\".txt\"\n",
    "    trace_handle=open(file_name, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9e821-129a-4135-9969-6bc2bb7e2a1b",
   "metadata": {},
   "source": [
    "다음 셀에서 위 목록의 질문으로 에이전트를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4fdd3-5e74-401a-8090-a3b95f68fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"Answer the following questions as best you can. Do not make up an answer. Think step by step. Do not perform intermediate math calculations on your own. Use the calculator tool provided for math calculations.\"\n",
    "\n",
    "for q in questions:\n",
    "    inputs = {\"messages\": [(\"system\",system_message), (\"user\", q)]}\n",
    "    config={\"recursion_limit\": 15}\n",
    "    print_stream(react_agent.stream(inputs, config, stream_mode=\"values\"))\n",
    "    print(\"\\n\"+\"================================ Answer complete =================================\"+\"\\n\")\n",
    "\n",
    "if trace_enabled:\n",
    "    trace_handle.close()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:797620947747:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
