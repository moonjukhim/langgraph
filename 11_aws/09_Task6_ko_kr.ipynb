{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adba6786",
   "metadata": {},
   "source": [
    "# íƒœìŠ¤í¬ 6: LangGraphì™€ Bedrock ëª¨ë¸ í†µí•©\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì—… ìˆœì„œë¥¼ ê²°ì •í•˜ê³ , ì´ë¥¼ êµ¬í˜„í•˜ëŠ” ê³„íš ë° ì‹¤í–‰ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "íŠ¹ì • ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì–¸ì–´ ëª¨ë¸ê³¼ ë‹¤ì–‘í•œ ìœ í‹¸ë¦¬í‹°ì— ëŒ€í•œ ì ì‘ ê°€ëŠ¥í•œ í˜¸ì¶œ ìˆœì„œë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤. LangChain ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤ëŠ” ìœ ì—°í•˜ë©°, ì™¸ë¶€ ë„êµ¬ì™€ LLMì˜ ì¶”ë¡ ì„ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¼ ì‚¬ìš©í•  ë„êµ¬ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° í•œ ë„êµ¬ì˜ ì¶œë ¥ì„ ë‹¤ìŒ ë„êµ¬ì˜ ì…ë ¥ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af1034",
   "metadata": {},
   "source": [
    "## íƒœìŠ¤í¬ 6.1: í™˜ê²½ ì„¤ì •\n",
    "\n",
    "ì´ íƒœìŠ¤í¬ì—ì„œëŠ” í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d84aafc-24b9-4129-86b1-4b06a9016821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:53:20.975676Z",
     "iopub.status.busy": "2025-10-16T03:53:20.975287Z",
     "iopub.status.idle": "2025-10-16T03:53:22.530680Z",
     "shell.execute_reply": "2025-10-16T03:53:22.529849Z",
     "shell.execute_reply.started": "2025-10-16T03:53:20.975643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.27\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: jupyter_ai_magics, langchain-community\n",
      "---\n",
      "Name: langchain-core\n",
      "Version: 0.3.79\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity, typing-extensions\n",
      "Required-by: amazon_sagemaker_jupyter_ai_q_developer, langchain, langchain-aws, langchain-community, langchain-text-splitters, langgraph, langgraph-checkpoint, langgraph-prebuilt\n",
      "---\n",
      "Name: langgraph\n",
      "Version: 0.6.10\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain langchain-core langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "717585b7-b0c0-4a30-be49-e0716716b5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:09:01.614492Z",
     "iopub.status.busy": "2025-10-16T07:09:01.614175Z",
     "iopub.status.idle": "2025-10-16T07:09:02.423397Z",
     "shell.execute_reply": "2025-10-16T07:09:02.422638Z",
     "shell.execute_reply.started": "2025-10-16T07:09:01.614466Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import pandas as pd\n",
    "import numexpr\n",
    "\n",
    "# LangChain / LangGraph imports\n",
    "from langchain.tools import tool\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96bd8701-e959-401b-b066-2ad2acea9542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:03.436509Z",
     "iopub.status.busy": "2025-10-16T07:15:03.436136Z",
     "iopub.status.idle": "2025-10-16T07:15:03.449117Z",
     "shell.execute_reply": "2025-10-16T07:15:03.448140Z",
     "shell.execute_reply.started": "2025-10-16T07:15:03.436486Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# ğŸ§° Tools ì •ì˜\n",
    "# ----------------------------------------\n",
    "\n",
    "@tool\n",
    "def lookup_price(item_name: str) -> str:\n",
    "    \"\"\"Lookup the price of a product by its name from the CSV file.\"\"\"\n",
    "    df = pd.read_csv(\"sales.csv\")\n",
    "    result = df[df[\"item\"] == item_name]\n",
    "    if result.empty:\n",
    "        return f\"'{item_name}' not found.\"\n",
    "    return str(result[\"price\"].values[0])\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression and return the result as a string.\"\"\"\n",
    "    try:\n",
    "        result = numexpr.evaluate(expression)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def echo_tool(text: str) -> str:\n",
    "    \"\"\"Echo back the provided text.\"\"\"\n",
    "    return f\"Echo: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb6f6fda-2b57-4d5b-a43a-c82d21215084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:05.981585Z",
     "iopub.status.busy": "2025-10-16T07:15:05.981260Z",
     "iopub.status.idle": "2025-10-16T07:15:05.994358Z",
     "shell.execute_reply": "2025-10-16T07:15:05.993630Z",
     "shell.execute_reply.started": "2025-10-16T07:15:05.981541Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# ğŸ§© Agent Node ìƒì„±\n",
    "# ----------------------------------------\n",
    "\n",
    "# Bedrock ëª¨ë¸ (ë˜ëŠ” í˜¸í™˜ ëª¨ë¸)\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",\n",
    "    region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37a1ddab-343c-46a2-b2e9-d05550981474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:06.909453Z",
     "iopub.status.busy": "2025-10-16T07:15:06.909178Z",
     "iopub.status.idle": "2025-10-16T07:15:06.925904Z",
     "shell.execute_reply": "2025-10-16T07:15:06.925135Z",
     "shell.execute_reply.started": "2025-10-16T07:15:06.909433Z"
    }
   },
   "outputs": [],
   "source": [
    "# ì‚¬ìš©í•  ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "tools = [lookup_price, calculator, echo_tool]\n",
    "\n",
    "# create_react_agent: LLMì´ ToolNodeë¥¼ í†µí•´ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ìë™ êµ¬ì„±\n",
    "agent = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4063c43-3120-44a1-b126-a288696179a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T07:15:09.928879Z",
     "iopub.status.busy": "2025-10-16T07:15:09.928614Z",
     "iopub.status.idle": "2025-10-16T07:15:13.695201Z",
     "shell.execute_reply": "2025-10-16T07:15:13.694363Z",
     "shell.execute_reply.started": "2025-10-16T07:15:09.928859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LangGraph ReAct Agent Example ===\n",
      "\n",
      "\n",
      "ğŸ¤– Agent Response:\n",
      "<thinking> The 'echo_tool' confirms that the item names are being correctly passed to the tools. However, the 'lookup_price' tool still seems to be malfunctioning. I will need to inform the user about the issue and suggest they check back later or contact support for assistance. </thinking>\n",
      "\n",
      "<response> I'm sorry, but I'm currently unable to look up the prices of the items due to a technical issue with the 'lookup_price' tool. Please check back later or contact support for assistance. </response>\n"
     ]
    }
   ],
   "source": [
    "print(\"=== LangGraph ReAct Agent Example ===\\n\")\n",
    "user_input = \"ì‚¬ìš©ì ì§ˆë¬¸:How much will it cost to buy 3 units of P002 and 5 units of P003?\"\n",
    "\n",
    "# âœ… agent ìì²´ê°€ ì‹¤í–‰ ê°€ëŠ¥í•œ Graphì…ë‹ˆë‹¤\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "\n",
    "print(\"\\nğŸ¤– Agent Response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef24bea",
   "metadata": {},
   "source": [
    "## íƒœìŠ¤í¬ 6.2: Synergizing Reasoning and Acting in Language Models í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "ì´ íƒœìŠ¤í¬ì—ì„œ ReAct í”„ë ˆì„ì›Œí¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ì™¸ë¶€ ë„êµ¬ì™€ ìƒí˜¸ ì‘ìš©í•˜ì—¬ ë³´ë‹¤ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì¶”ê°€ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ì¶”ë¡ ì— ëŒ€í•œ ì„¤ëª…ê³¼ ì‘ì—…ë³„ ì‘ë‹µì„ êµëŒ€ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì¶”ë¡  ì„¤ëª…ì„ ìƒì„±í•˜ë©´ ëª¨ë¸ì´ ì‹¤í–‰ ê³„íšì„ ì¶”ë¡ , ëª¨ë‹ˆí„°ë§ ë° ìˆ˜ì •í•  ìˆ˜ ìˆê³ , ì˜ˆìƒì¹˜ ëª»í•œ ì‹œë‚˜ë¦¬ì˜¤ë„ ì²˜ë¦¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ë‹¨ê³„ì—ì„œ ëª¨ë¸ì€ ì§€ì‹ ê¸°ë°˜ ë˜ëŠ” í™˜ê²½ê³¼ ê°™ì€ ì™¸ë¶€ ì†ŒìŠ¤ì™€ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì •ë³´ë¥¼ íšë“í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1defc7f-4475-4071-9ab3-ff5806d068d1",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ì…€ì—ì„œëŠ” Langchain í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ë„êµ¬ ì—­í• ì„ í•˜ëŠ” `calculator` í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ì–¸ì–´ ëª¨ë¸ì´ Pythonì˜ numexpr ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ì£¼ì–´ì§„ ì‹ì„ í‰ê°€í•˜ì—¬ ìˆ˜í•™ì  ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ì‹ì´ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ì´ ë„êµ¬ëŠ” ê³„ì‚°ì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ ì¬ê³ í•˜ë„ë¡ ëª¨ë¸ì— ìš”ì²­í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6155c82-eb40-4eff-b5d5-d9fec4905278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:56:45.279830Z",
     "iopub.status.busy": "2025-10-16T03:56:45.279513Z",
     "iopub.status.idle": "2025-10-16T03:56:45.291514Z",
     "shell.execute_reply": "2025-10-16T03:56:45.290747Z",
     "shell.execute_reply.started": "2025-10-16T03:56:45.279808Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def lookup_price(query: str) -> str:\n",
    "    \"\"\"Look up a product price from a CSV file.\n",
    "    Expected query: product_id (or line with product_id on first line)\n",
    "    The original notebook used a CSV file; adapt the path as needed.\n",
    "    \"\"\"\n",
    "    csv_path = os.environ.get(\"PRICES_CSV\", \"prices.csv\")\n",
    "    prices = {}\n",
    "    if not os.path.exists(csv_path):\n",
    "        return f\"Price CSV not found at {csv_path}\"\n",
    "    try:\n",
    "        with open(csv_path, newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                prices[row.get('product_id') or row.get('id')] = row.get('price')\n",
    "    except Exception as e:\n",
    "        return f\"Failed to read CSV: {e}\"\n",
    "\n",
    "    qstr = query.split('\\n')[0].strip()\n",
    "    price = prices.get(qstr)\n",
    "    if price is None:\n",
    "        return f\"Price for product {qstr} is not available\"\n",
    "    return f\"Price of product {qstr} is {price}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce2b82-438c-4b13-a941-74c79d6526c3",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ì…€ì—ì„œëŠ” Langchain í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ë„êµ¬ ì—­í• ì„ í•˜ëŠ” `calculator` í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë©´ ì–¸ì–´ ëª¨ë¸ì—ì„œ Pythonì˜ numexpr ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì£¼ì–´ì§„ í‘œí˜„ì‹ì„ í‰ê°€í•˜ì—¬ ìˆ˜í•™ì  ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‘œí˜„ì‹ì´ ìœ íš¨í•˜ì§€ ì•Šì€ ì‚¬ë¡€ê°€ ì²˜ë¦¬ë˜ë„ë¡ ë„êµ¬ê°€ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ì‚¬ë¡€ì—ì„œëŠ” ê³„ì‚°ì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ ì¬ê³ ë¥¼ ëª¨ë¸ì— ìš”ì²­í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4c3256c-0806-4a19-ad42-4a2153f9ea9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:57:03.116611Z",
     "iopub.status.busy": "2025-10-16T03:57:03.116272Z",
     "iopub.status.idle": "2025-10-16T03:57:03.122942Z",
     "shell.execute_reply": "2025-10-16T03:57:03.122081Z",
     "shell.execute_reply.started": "2025-10-16T03:57:03.116589Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a math expression and return the result as string.\n",
    "    Uses numexpr for basic arithmetic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # strip natural-language wrappers if user sent 'compute: 5*4' etc.\n",
    "        expr = expression.strip()\n",
    "        # Evaluate using numexpr to limit operations\n",
    "        result = numexpr.evaluate(expr, global_dict={}, local_dict={})\n",
    "        return str(result)\n",
    "    except Exception:\n",
    "        return \"Error evaluating expression. Please provide a valid math expression.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ad97004-e7b8-4479-b966-2b276f8e55ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T03:59:13.468032Z",
     "iopub.status.busy": "2025-10-16T03:59:13.467741Z",
     "iopub.status.idle": "2025-10-16T03:59:13.487631Z",
     "shell.execute_reply": "2025-10-16T03:59:13.486990Z",
     "shell.execute_reply.started": "2025-10-16T03:59:13.468009Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def echo_tool(text: str) -> str:\n",
    "    \"\"\"Lookup the price of a product by its name from the CSV file.\"\"\"\n",
    "    return text\n",
    "\n",
    "# Bind tools to the LLM\n",
    "tools = [lookup_price, calculator, echo_tool]\n",
    "tools_by_name = {t.name: t for t in tools}\n",
    "llm_with_tools = chat_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "642ed754-8a53-4485-8164-aab5f8be60a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:10:46.554372Z",
     "iopub.status.busy": "2025-10-16T05:10:46.554109Z",
     "iopub.status.idle": "2025-10-16T05:10:46.561264Z",
     "shell.execute_reply": "2025-10-16T05:10:46.560519Z",
     "shell.execute_reply.started": "2025-10-16T05:10:46.554351Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 3: Define shared state type ---\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int\n",
    "\n",
    "# --- Step 4: Define nodes ---\n",
    "# Model node: ask the model to decide next step / produce a message\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant. Use the available tools when needed.\"\n",
    "\n",
    "def llm_node(state: MessagesState):\n",
    "    \"\"\"Call the LLM (with tools) and append its response to state['messages']\"\"\"\n",
    "    # Build messages: include a system message followed by the conversation\n",
    "    msgs = [SystemMessage(content=SYSTEM_PROMPT)] + state.get(\"messages\", [])\n",
    "    response = llm_with_tools.invoke(msgs)\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"llm_calls\": state.get(\"llm_calls\", 0) + 1,\n",
    "    }\n",
    "\n",
    "# Tool node: execute tool calls that the LLM requested\n",
    "def tool_node(state: MessagesState):\n",
    "    \"\"\"Perform any tool calls found on the last LLM message and return ToolMessage objects.\"\"\"\n",
    "    result = []\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        return {\"messages\": []}\n",
    "\n",
    "    last = messages[-1]\n",
    "    # In LangChain message objects, tool calls live in `.tool_calls` on the message\n",
    "    tool_calls = getattr(last, \"tool_calls\", []) or []\n",
    "    for tool_call in tool_calls:\n",
    "        # tool_call expected shape: {\"name\": ..., \"args\": ...}\n",
    "        tool_name = tool_call.get(\"name\")\n",
    "        args = tool_call.get(\"args\", {})\n",
    "        if tool_name not in tools_by_name:\n",
    "            obs = f\"Tool {tool_name} not found\"\n",
    "        else:\n",
    "            obs = tools_by_name[tool_name].invoke(args)\n",
    "        # Create a ToolMessage with the observation\n",
    "        tm = ToolMessage(content=obs, tool_call_id=tool_call.get(\"id\"))\n",
    "        result.append(tm)\n",
    "    return {\"messages\": result}\n",
    "\n",
    "# --- Step 5: Edge decision function: continue if model made a tool call ---\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        return END\n",
    "    last = messages[-1]\n",
    "    if getattr(last, \"tool_calls\", None):\n",
    "        return \"tool_node\"\n",
    "    return END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a0ac1-d256-4188-b6b7-22a5f6960d34",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ì…€ì—ì„œëŠ” helper í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¶”ì  ì¶œë ¥ì„ íŒŒì¼ì— ì¸ì‡„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5321facb-cfc9-4e86-a669-db6dbdf116b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:10:55.626253Z",
     "iopub.status.busy": "2025-10-16T05:10:55.625980Z",
     "iopub.status.idle": "2025-10-16T05:10:55.631038Z",
     "shell.execute_reply": "2025-10-16T05:10:55.630178Z",
     "shell.execute_reply.started": "2025-10-16T05:10:55.626229Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "def output_trace(element:str, trace, node=True):\n",
    "    global trace_handle\n",
    "    if trace_enabled:\n",
    "        print(datetime.datetime.now(),file=trace_handle)\n",
    "        print((\"Node: \" if node else \"Edge: \")+ element, file=trace_handle)\n",
    "        if element == \"ask_model_to_reason (entry)\":\n",
    "            for single_trace in trace:\n",
    "                print(single_trace, file=trace_handle)\n",
    "        else:\n",
    "            print(trace, file=trace_handle)\n",
    "        print('----', file=trace_handle)\n",
    "        \n",
    "def consolidate_tool_messages(message):\n",
    "    tool_messages=[]\n",
    "    for msg in message:\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            tool_messages.append(msg)\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320f3b2",
   "metadata": {},
   "source": [
    "## íƒœìŠ¤í¬ 6.3: ì—ì´ì „íŠ¸ ê·¸ë˜í”„ êµ¬ì¶•\n",
    "\n",
    "ì´ íƒœìŠ¤í¬ì—ì„œëŠ” ì™¸ë¶€ ë„êµ¬ì™€ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• AI ì‹œìŠ¤í…œìš© ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ ê·¸ë˜í”„ëŠ” ë„êµ¬ì™€ì˜ ëŒ€í™” ë° ìƒí˜¸ ì‘ìš© íë¦„ì´ ì •ì˜ë˜ëŠ” ìƒíƒœ ë¨¸ì‹ ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì…€ì—ì„œëŠ” ì…ë ¥ì— ë”°ë¼ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê´€ë ¨ í•¨ìˆ˜ê°€ ìˆëŠ” ë…¸ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ê·¸ë˜í”„ê°€ í•œ ë…¸ë“œì—ì„œ ë‹¤ìŒ ë…¸ë“œë¡œ ì „í™˜ë˜ëŠ” ê°€ì¥ìë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œë¥¼ ì—°ê²°í•©ë‹ˆë‹¤. ì¡°ê±´ë¶€ ì—ì§€ë¥¼ í†µí•©í•˜ì—¬ íŠ¹ì • ì¡°ê±´ì— ë”°ë¼ ê·¸ë˜í”„ë¥¼ ë‹¤ë¥¸ ë…¸ë“œë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ì—¬ ì •ì˜ëœ ëŒ€ë¡œ ì „í™˜ ë° ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì‹¤í–‰ì„ ì¤€ë¹„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b51b843-3660-4929-bbc9-af859be41260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:11:44.300200Z",
     "iopub.status.busy": "2025-10-16T05:11:44.299923Z",
     "iopub.status.idle": "2025-10-16T05:11:44.307613Z",
     "shell.execute_reply": "2025-10-16T05:11:44.306817Z",
     "shell.execute_reply.started": "2025-10-16T05:11:44.300178Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 6: Build and compile the StateGraph ---\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "agent_builder.add_node(\"llm_node\", llm_node)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# Connect start to llm_node\n",
    "agent_builder.add_edge(START, \"llm_node\")\n",
    "# Conditional: if llm created tool calls -> tool_node else END\n",
    "agent_builder.add_conditional_edges(\"llm_node\", should_continue, [\"tool_node\", END])\n",
    "# After executing tools, go back to llm\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_node\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db097971-db69-4c8f-a08a-9686b5a1ad72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T05:13:13.994398Z",
     "iopub.status.busy": "2025-10-16T05:13:13.994118Z",
     "iopub.status.idle": "2025-10-16T05:13:15.885394Z",
     "shell.execute_reply": "2025-10-16T05:13:15.884702Z",
     "shell.execute_reply.started": "2025-10-16T05:13:13.994377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking agent with example messages...\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 5*7?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "P001\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"<thinking>The User has asked for a simple multiplication calculation. The 'calculator' tool can be used to safely evaluate the expression.</thinking>\\n\"}, {'type': 'tool_use', 'name': 'calculator', 'input': {'expression': '5*7'}, 'id': 'tooluse_eCrh6WQdSxOQxmqGlD0Cyg'}]\n",
      "Tool Calls:\n",
      "  calculator (tooluse_eCrh6WQdSxOQxmqGlD0Cyg)\n",
      " Call ID: tooluse_eCrh6WQdSxOQxmqGlD0Cyg\n",
      "  Args:\n",
      "    expression: 5*7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "35\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of the multiplication 5 * 7 is 35.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "user_messages = [HumanMessage(content=\"What is 5*7?\"), HumanMessage(content=\"P001\")]\n",
    "initial_state = {\"messages\": user_messages, \"llm_calls\": 0}\n",
    "\n",
    "print(\"Invoking agent with example messages...\\n\")\n",
    "out = agent.invoke(initial_state)\n",
    "# The agent returns a dict-like state; print messages\n",
    "messages_out = out.get(\"messages\", [])\n",
    "for m in messages_out:\n",
    "    try:\n",
    "        m.pretty_print()\n",
    "    except Exception:\n",
    "        print(repr(m))\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ba496-f4e8-459c-a8e0-1add96724640",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ ì»´íŒŒì¼ëœ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. ì ì„ ìœ¼ë¡œ í‘œì‹œëœ ê²ƒì²˜ëŸ¼ ì—ì´ì „íŠ¸ ë…¸ë“œì—ì„œ ì¡°ê±´ë¶€ë¡œ ì „í™˜ë˜ëŠ” ê²ƒì„ ê´€ì°°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe11dc-4a20-4f82-82a0-7a2b21261ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(react_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12e190-6682-422b-a7e7-902baeab368f",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ì…€ì—ì„œëŠ” helper í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ê·¸ë˜í”„ ì¶œë ¥ì„ ì¸ì‡„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e1a56-983e-4fb7-95e2-f1045d22bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a02d2-d337-40cd-ae33-52d168954345",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ìƒì„±í•œ sales.csv íŒŒì¼ì—ì„œ ì—ì´ì „íŠ¸ì—ê²Œ ì œí’ˆ ê°€ê²©ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³  ì‹¶ì€ ì§ˆë¬¸ì„ í•˜ë‚˜ ì´ìƒ ì¶”ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93542a4-00e1-4778-801f-54000bedd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of questions\n",
    "questions=[]\n",
    "questions.append(\"How much will it cost to buy 3 units of P002 and 5 units of P003?\")\n",
    "#questions.append(\"How many units of P010 can I buy with $200?\")\n",
    "#questions.append(\"Can I buy three units of P003 with $200? If not, how much more should I spend to get three units?\")\n",
    "#questions.append(\"Prices have gone up by 8%. How many units of P003 could I have purchased before the price increase with $140? How many can I buy after the price increase? Fractional units are not pssoible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2fdc8-7491-4b9b-a7b7-d4f7b909140b",
   "metadata": {},
   "source": [
    "ì¶”ë¡ ì— í¬í•¨ëœ ë‹¨ê³„ë¥¼ ì´í•´í•˜ë ¤ë©´ ì¶”ì ì„ í™œì„±í™”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ìœ„ ëª©ë¡ì—ì„œ **í•œ ê°œì˜ ì§ˆë¬¸ì„ ì œì™¸í•œ ëª¨ë“  ì§ˆë¬¸ì„ ì£¼ì„ ì²˜ë¦¬**í•˜ì—¬ ì¶”ì  ì¶œë ¥ì„ ê´€ë¦¬í•˜ê¸° ì‰½ê²Œ ìœ ì§€í•©ë‹ˆë‹¤. ë˜ëŠ” ì¶”ì ì„ ë¹„í™œì„±í™”í•˜ê³  ëª¨ë“  ì§ˆë¬¸ì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286029b4-a16c-405c-9280-961c1e9378a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_enabled=True\n",
    "\n",
    "if trace_enabled:\n",
    "    file_name=\"trace_\"+str(datetime.datetime.now())+\".txt\"\n",
    "    trace_handle=open(file_name, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9e821-129a-4135-9969-6bc2bb7e2a1b",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ì…€ì—ì„œ ìœ„ ëª©ë¡ì˜ ì§ˆë¬¸ìœ¼ë¡œ ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4fdd3-5e74-401a-8090-a3b95f68fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"Answer the following questions as best you can. Do not make up an answer. Think step by step. Do not perform intermediate math calculations on your own. Use the calculator tool provided for math calculations.\"\n",
    "\n",
    "for q in questions:\n",
    "    inputs = {\"messages\": [(\"system\",system_message), (\"user\", q)]}\n",
    "    config={\"recursion_limit\": 15}\n",
    "    print_stream(react_agent.stream(inputs, config, stream_mode=\"values\"))\n",
    "    print(\"\\n\"+\"================================ Answer complete =================================\"+\"\\n\")\n",
    "\n",
    "if trace_enabled:\n",
    "    trace_handle.close()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:797620947747:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
